---
layout: post
title:  不掌握这项Java技能，还敢说大数据时代的程序员
tagline: by simsky
categories: JDK 新特性
tags: 
    - simsky

---

大家好，我是指北君，在如今的大数据时代，对于数据的生产线式的加工处理场景越来越多，Java8之前对于这种类型的数据处理是显得有些笨拙的，代码繁多臃肿（过多的中间过程变量和过程），显得不够优雅和简洁。在Java8引入Stream包后，我们就可以得心应手地应付这种场景。

<!--more-->
##


### 什么是Stream
不知道有玩过异星工厂的伙伴没，给一张图

![生产线](/assets/images/2021/simsky/jdk_stream_1.png)

Stream就像处理生产流水线一样去工作，传送带就是Stream的管道，手臂
为什么要比传统的处理方式好呢？我们看看下去，传统的方式我们要有循环控制，逻辑控制，解包，重新装箱，每个环节都要重复这些工作。

![非生产线示意处理图](/assets/images/2021/simsky/jdk_stream_2.png)

每一个环节都要进行控制，判断，拆箱，数据处理逻辑，装箱。使用Stream后我们只关注数据处理逻辑，其他的事情交给流处理对应的方法来完成。

### 创建数据流
有很多种创建Stream的方式，流一旦创建后，修改创建的源不会影响已经创建的Stream中的数据。
1. 空流
为了避免出现空指针异常，系统提供一个静态方法提供空流。
```java
    public void createStream() {
        Stream<String> myStream = Stream.empty();
    }
```

2. 通过数组对象创建流
```java
    public void createStream() {
        Integer[] arr = new Integer[]{1,2,3};
        Stream<Integer> stream1 = Arrays.stream(arr);
        Stream<Integer> stream2 = Arrays.stream(arr, 0, 2);
    }
```

3. 通过集合对象创建流
```java
    public void createStream() {
        Collection<String> collection = Arrays.asList("a", "b", "c");
        Stream<String> stream1 = collection.stream();
    }
```
支持多种集合：List，Set，Map等实现了Collection接口的集合对象。

4. 通过builder创建
```java
    public void createStream() {
        Stream<Long> stream1 =
                  Stream.<Long>builder().add(1L).add(2L).add(3L).build();
    }
```

5. 通过generate生成
```java
    public void createStream() {
        Random r = new Random();
        Stream<Long> stream =
                  Stream.generate(() -> r.nextLong()).limit(10);
    }
```
按照提供给generate的Supplier逻辑生成数据，通过limit限制生成的数据量

6. 通过Stream.iterate创建
```java
    public void createStream() {
        Stream<Integer> stream = Stream.iterate(1, n -> n * n).limit(20);
    }
```
iterate提供两种方法来满足我们比较常用的迭代生成逻辑
+ iterate(final T seed, final UnaryOperator<T> f) 
+ iterate(T seed, Predicate<? super T> hasNext, UnaryOperator<T> next)

7. 原生类型生成
通过对应的IntStream,LongStream,DoubleStream类中提供的方法来获取，包含常用的方法
+ builder()
+ empty()
+ of()
+ iterate()
+ generate()
+ range()
+ concat()

8. 其他地方
这里介绍两处：字符分割匹配和文件行数据

String.chars()返回IntStream
Files.lines()返回通过行分割的字符内容

### 流的使用机制（重要事项）
我们通过上面的方法创好流后，我们就可以对流进行相关的业务逻辑处理了，但是一旦我们操作过一次后再想继续操作，就会出错，系统会爆出IllegalStateException异常，这是应为Stream设计为不可重用的模式。我们的下一个环节都是对当前环节处理后新生成流的处理。

### 流的执行顺序
采用Stream方式进行连续的时，他们之间的执行顺序是什么样的呢？我写一段测试代码
```java
    public void exeOrder() {
        List<String> list = Arrays.asList("data_1","data_2", "data_3", "data_12");
        list.stream().filter(x -> {
            System.out.println("filter() was called: " + x);
            return x.contains("2");
        }).map(x -> {
            System.out.println("map() was called: " + x);
            return x.toUpperCase();
        }).forEach(x->System.out.println("forEach() was called: " + x));
    }
```

filter() was called: abc1
filter() was called: abc2
map() was called: abc2
forEach() was called: ABC2
filter() was called: abc3
filter() was called: abc12
map() was called: abc12
forEach() was called: ABC12

从示例代码的打印的顺序中我们可以发现：流处理的顺序不是以代码逻辑执行完一步再到下一步，而是按照数据处理完一个单位数据的所有环节再处理下一个数据，见下面的动态示意图：

![Stream处理顺序](/assets/images/2021/simsky/jdk_stream_100.gig)

既然我们了解流的处理顺序，那么对于某些流操作是会提前结束流处理的，比如findFirst(),在处理完第一个符合条件的数据后，后续的数据不会参与任何一个环节的处理。

###  转换处理
介绍转换处理的文章较多，这里不再一一详细描述只是简单列一下，转换处理对应大数据MapReduce中的Map处理
1. distinct剔重
2. filter过滤
3. map转换映射
4. peek 
5. limit
6. skip

### 合并处理（reduce）
对于Map-Reduce模型的reduce操作，国内对这个词翻译不太统一，指北君就先称之为合并处理吧。这里介绍两个方法reduce和collect
1. reduce
先来看一个reduce的示例
```java
    public void reduce() {
        int sum = IntStream.range(1, 100).reduce(0, (a, b) -> a + b);
        System.out.print(sum);
    }
```
合并Stream中的所有值，合并的初始值为0，如果初始为0还可以沈略初始值。
reduce函数包含三部分关键信息：
+ 初始值，由于做合并初始的初始值
+ 合并函数
+ 合路器，在并行（多线程）运算时需要用到

下面是一个使用合路器的示例，在并行运算时使用。
```java
    public void parallelReduce() {
        int sum = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10).parallelStream()
                .reduce(0, (a, b) -> a + b, (a, b) -> {
                   return a + b;
                });
        System.out.println(sum);
    }
```
这个库指北君留一道作业题给大家思考，如果这里初始值0修改为10，最终的结果是多少？为什么是这种结果呢？

2. collect
现在我们再来看collect，collect严格上说时reduce有些牵强，因为是否reduce在于collect中的执行逻辑
比如这段：
```java
List<String> collector =  list.stream().map(Product::getName).collect(Collectors.toList());
```

下面的例子：
```java
String mergString = list.stream().map(Product::getName).collect(Collectors.joining(", ", "[", "]"));
```

还有其他对应的方法：
+ Collectors.averagingInt
+ Collectors.summingInt
+ Collectors.groupingBy
+ Collectors.partitioningBy

各位小伙伴可以查看Collectors对应的API，这里就不一一列举了，总之，collect通过Collectors对象的API类完成合并处理。


### 总结

关于Java的Stream的常用知识指北君就给大家分享到这，相关的重点知识都有提及，但未太深入剖析，比如Stream的并发处理是如何执行的等等，这些知识点留待后续指北君为大家分享。

最后感谢各位人才的：点赞、收藏和评论，我们下期更精彩！

